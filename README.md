AI-Визажист: Telegram Бот
Телеграм-бот, который консультирует по вопросам макияжа с помощью AI-модели (Llama 3.1 или ваш вариант). Бот запоминает историю диалога с каждым пользователем, сохраняя ее в базу данных PostgreSQL.

Требования
Python 3.8+
Docker
Аккаунт на Hugging Face с созданным Read-токеном.
Токен Telegram-бота, полученный от @BotFather.
Быстрый запуск
1. Установка зависимостей
Bash

pip install -r requirements.txt
2. Настройка токенов
Создайте файл secrets.py в корневой директории проекта. В этом файле будут храниться ваши API-токены. Добавьте в него следующее содержимое, подставив ваши значения:

Python

# secrets.py

secrets = {
    'BOT_API_TOKEN': 'сюда_вставьте_токен_вашего_бота',
    'HF_TOKEN': 'сюда_вставьте_ваш_read-токен_от_hugging_face'
}
Примечание: Файл secrets.py добавлен в .gitignore, чтобы предотвратить случайную утечку ваших учетных данных.

3. Запуск базы данных
Запустите PostgreSQL в Docker-контейнере.

Bash

docker run --name my-postgres-tgbot -e POSTGRES_PASSWORD=mysecretpassword -p 5433:5432 -d postgres:15-alpine
(Если контейнер уже был создан ранее, вы можете просто запустить его командой docker start my-postgres-tgbot.)

4. Запуск бота
Bash

python bot.py
Использование
Начать диалог: Просто отправьте боту любое сообщение, чтобы начать.
Сбросить историю: Используйте команду /reset или кнопку "RESET", чтобы очистить историю вашей переписки с ботом.
Архитектура проекта
Проект имеет двухкомпонентную структуру для разделения ответственности: фронтенд для обработки взаимодействий с Telegram и бэкенд для обработки логики с AI и базой данных.

plaintext

/
├── bot.py             # Фронтенд Telegram-бота (обработка взаимодействия с пользователем)
├── llm_service.py     # Бэкенд-сервис (управление AI-моделью и подключением к БД)
├── secrets.py         # Хранит API-токены (не отслеживается Git)
├── requirements.txt   # Зависимости Python
└── README.md          # Этот файл
Описание компонентов
bot.py (Фронтенд): Этот скрипт отвечает за все взаимодействия с Telegram Bot API. Он получает сообщения от пользователей, отправляет их в бэкенд-сервис для обработки и доставляет сгенерированные AI-ответы обратно пользователю.

llm_service.py (Бэкенд): Это ядро приложения. Он выступает в роли микросервиса, который:

Подключается к базе данных PostgreSQL для получения и сохранения истории диалога.
Управляет контекстом для AI-модели.
Взаимодействует с Hugging Face API для получения ответов от модели Llama 3.1.
Такое разделение обеспечивает лучшую масштабируемость и упрощает поддержку. Фронтенд можно разрабатывать независимо от логики бэкенда, а бэкенд можно оптимизировать или даже полностью заменить, не затрагивая пользовательскую часть бота.






